# (PART) Part One {-}

# History & Exemplars {#history}

## Reproducible Research

So why is reproducible research important and incredibly beneficial? Let's take a look at its beginnings to find the answer. 

In the early '90s, a geophysicist named Jon Claerbout revised his book Earth Soundings Analysis with a valid complaint. He claimed that few published results are reproducible in any practical sense. To verify them requires almost as much effort as it took to create them in the first place. After a time, even the authors are often unable to reproduce their own results! For these reasons, many people ignore most of the literature.

Then, in 1996, the Consolidated Standards of Reporting Trials (or CONSORT) published a set of guidelines to fix problems that developed from inadequate reporting of randomized controlled trials. Following their lead, in 2004, the International Committee of Medical Journal Editors stated they wouldn't publish a clinical trial that had not been registered, and that they would only endorse registries meeting several key criteria, including that they must be: 

* free and publicly accessible, 
* open to all prospective registrants, 
* managed by a non-profit organization, and
* electronically searchable and validated

As a result of this turmoil in validity and research, the Food and Drug Administration got on board and required the registration of even more clinical trials. The Journal of Biostatistics also encouraged reproducible practices  of author submissions. They began marking accepted papers based on the standards of reproducibility that were followed. For example, papers marked with a 'D' marking meant the data on which the study is based is freely available. A 'C' marking means the authors' code is freely available. And an 'R' marking is the gold standard, meaning that not only are the data and code freely available, but the associate editor for reproducibility was also able to reproduce the same results as the paper. 

An example of an article given the highest designation for a fully reproducible article is one published in 2009 entitled “Air pollution and health in Scotland: a multicity study.” To see the article's marking, you have to download the PDF and look for the marking letter in a bold box at the top right. 

Most compelling, in the early 2000s, John Ioannidis published an article with the highest downloads in the history of the Public Library of Science. It was entitled "Why most published research findings are false." Despite multiple organizations attempting to fix this issue, the Open Science Collaboration revealed in 2015 that they were only able to reproduce or replicate between 30-50% of the results from more than 100 studies. Ziemann, et.al. in 2016 also found that 20% of papers published in leading genomics journals have supplementary data files containing erroneous gene name conversions due to Microsoft Excel default settings. This 20% is an average, and some journals have even higher rates.

But this isn't new. In 2011, Alsheikh-Ali [Al shake], et.al. assessed 500 research papers with unsettling results. Of these 500 papers sent to high-impact research journals, 30% were not subject to any data availability policy. The papers that adhered to the data availability instructions did so by publicly depositing only the specific data type as required, making a statement of willingness to share, or actually sharing all the primary data. Overall, only 47 papers (that's only 9%!) deposited full primary raw data online. 

In the last several years, reproducibility errors have been at the center of some major controversies. In 2010, a published cancer clinical trial at Duke University was tested by two MD Anderson researchers, Keith Baggerly and Kevin Coombs. They found numerous spreadsheet errors leading to misalignment and incorrect assignment of cancer treatment therapies. Because of this, four papers published by the Duke team were retracted, the Duke lead scientist resigned, and Duke shut down three other trials using these results, and many patients have pursued legal action. 

Another famous study, often called the “excel-error heard round the world” – was based on a paper by two well-known economists at Harvard, Kenneth Rogoff and Carmen Reinhart. In their paper “Growth in a Time of Debt”, the authors claimed that countries whose debt exceeds 90 percent of their annual gross domestic product experience slower growth than countries with lower debt — a figure that's been cited by many people in order to justify slashing government spending. But when Thomas Herndon, a 28-year-old economics graduate student at the University of Massachusetts tried to reproduce the results, he discovered a major formula error in the excel data spreadsheet. The original paper had excluded key data from the countries of Canada, New Zealand, and Australia — all countries that experienced solid growth during periods of high debt and thus undercut the conclusion that high debt forestalls growth. 

Due to these critical moments in the last few decades, reproducibility continues to grow as new policies are adopted and the practices are applied. But part of the benefit of being in this course is that you get to be part of the reproducible research movement!

## Literate Programming

In 1991, around the same time Jon Claerbout coined the term “reproducible research”, the computer scientist, Donald Knuth, introduced the concept of “literate programming.” The idea of literate programming is that software/computer programs are written in a language humans can understand rather than a language only machines can understand. In literate programming, computer code is embedded within the program's documentation as opposed to the documentation embedded within computer code; the code follows the structure of the documentation.

The program that Donald Knuth used to implement his idea of “literate programming” was called WEB, which he introduced in 1981. WEB linked the TeX typesetting or formatting system for creating documents with the Pascal computer programming language. WEB was one of the first systems to directly link documentation creation and typesetting with computer programming. Donald Knuth chose the name WEB because it implied a program of ideas pieced together from simple materials.

Since WEB was introduced, many other programs implementing literate programming have emerged. Here are a few to give you an idea of the variety available.

* CWEB also created by Donald Knuth with Silvio Levy which was adapted for the C and C++ compute language instead of Pascal
* Axiom developed by IBM
* Noweb
* Literate
* Funnel WEB
* Molly 
* Codnar
* Jupyter Notebook (formerly IPython Notebook) and
* R Notebooks

## Dynamic Documentation

So literate programming is an approach that moves away from writing computer programs in a high-level machine language and instead combines programming language with documentation language so that the program reads almost like an essay or a piece of literature. But what about dynamic documentation? Dynamic documentation allows for constant change and is a tool that provides up-to-date reports if certain components, such as data or analysis, change.

In 2002, Friederich Leisch, a statistics professor from the University of Natural Resources and Life Sciences in Vienna, released the SWEAVE program for dynamic documentation generation. Notably, SWEAVE allows R code to be embedded within LaTeX documents. LaTeX is  a more modern version of the TeX typesetting program used by Donald Knuth. The really exciting feature of literate programming and dynamic documentation is highlighted in what Friedrich Leisch says about SWEAVE: since the underlying computer code is wholly integrated within the document itself, anytime there are changes to the underlying data or analyses or code, the report itself is automatically updated ON THE FLY!

The next evolution of ideas for literate programming and dynamic documentation have emerged from the R programming and RStudio communities. In 2012, Yihui Xie (yeewhay she) released the R package called knitr. This package was inspired by SWEAVE, and thus combines R code with text typesetting for producing documents. Like SWEAVE, knitr works with LaTeX but it also works with rmarkdown, which uses simple text markup syntax based on the original “markdown” package. The primary “markdown” package was introduced by John Gruber in 2004 to make it easier to “markup” plain text files for generating HTML documents – ideally without having to learn HTML. The rmarkdown package you’ll use throughout this course is built upon John Gruber’s “markdown”.

Rmarkdown itself was fully released in 2014 and its original objective was creating documents for the internet by creating HTML formatted documents. However, the “rmarkdown” package also leverages Pandoc for creating an even wider array of documentation formats – including:

* The DOC format, as used by Microsoft WORD or Google Docs
* The ODT format used by Libre Office
* The PDF format 
* EPUB for electronic-books
* Slide shows using HTML5
* And the original TeX document formats and related TeX based slide formats like Beamer.

In this course, you won't interact directly with Pandoc, but it has been bundled with RStudio since 2015– so when you install RStudio, you'll also get the functionality of Pandoc. If you would like to learn more about Pandoc, you can visit their website at pandoc.org. Since Pandoc can convert many different document formats, it's often called the “swiss army knife” for document conversion. Pandoc is extremely versatile, allowing conversion between HTML web-based formats, word processor type formats, electronic publishing (or EPUB) formats,  presentation slide-based formats, publication layout formats, TeX based formats, and many others.

Ultimately, the RStudio Interactive Development Environment becomes our central “HUB” for combining the capabilities of:

* The great packages of “knitr” and “rmarkdown” 
* with the built-in functionality of Pandoc for document conversion
* plus the fantastic analysis and graphics capabilities of the R programming language.

From the RStudio interface, we can access all of this functionality and create documents on the fly in multiple formats for multiple end uses and products.


